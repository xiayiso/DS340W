{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec55b7a2",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-09-29T17:07:04.708972Z",
     "iopub.status.busy": "2021-09-29T17:07:04.708077Z",
     "iopub.status.idle": "2021-09-29T17:07:31.945245Z",
     "shell.execute_reply": "2021-09-29T17:07:31.944106Z",
     "shell.execute_reply.started": "2021-09-29T17:07:04.708831Z"
    },
    "papermill": {
     "duration": 0.011209,
     "end_time": "2022-01-13T14:27:36.788378",
     "exception": false,
     "start_time": "2022-01-13T14:27:36.777169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "!pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00eddb19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:27:36.910401Z",
     "iopub.status.busy": "2022-01-13T14:27:36.814745Z",
     "iopub.status.idle": "2022-01-13T14:31:49.461723Z",
     "shell.execute_reply": "2022-01-13T14:31:49.461094Z",
     "shell.execute_reply.started": "2022-01-13T13:54:00.969285Z"
    },
    "papermill": {
     "duration": 252.663091,
     "end_time": "2022-01-13T14:31:49.461943",
     "exception": false,
     "start_time": "2022-01-13T14:27:36.798852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If for semantic segmentation, please install mmsegmentation first\n",
      "If for detection, please install mmdetection first\n",
      "1.4.4\n",
      "height_mean904.2843018563358_std156.90598049629264\n",
      "width_mean804.4262510088781_std270.21192072081044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 186.10it/s]\n",
      "100%|██████████| 5/5 [01:04<00:00, 12.82s/it]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "100%|██████████| 5/5 [00:52<00:00, 10.48s/it]\n",
      "100%|██████████| 5/5 [00:55<00:00, 11.08s/it]\n",
      "100%|██████████| 5/5 [00:49<00:00,  9.96s/it]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "sys.path.append('../input/pythonbox')\n",
    "from box import Box\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "from timm import create_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from pytorch_grad_cam import GradCAMPlusPlus\n",
    "#from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "sys.path.append('../input/poolformer-master')\n",
    "import models as PoolFormerModels #poolformer\n",
    "\n",
    "print(pl.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "config_ensemble = {'exp_name':'exp073',\n",
    "            'seed': 2021,\n",
    "              'n_splits': 5,\n",
    "              'oof_expname':{\n",
    "                  1:'exp049',\n",
    "                  2:'exp054',\n",
    "                  3:'exp060',\n",
    "                  4:'exp065',\n",
    "                  5:'exp069',\n",
    "                  6:'exp074',\n",
    "              },\n",
    "              'model':'Ridge'\n",
    "}\n",
    "\n",
    "config_ensemble = Box(config_ensemble)\n",
    "\n",
    "#049\n",
    "config_exp049 = {'exp_name':'exp049',\n",
    "            'seed': 2021,\n",
    "          'root': '/kaggle/input/petfinder-pawpularity-score/', \n",
    "          'n_splits': 5,\n",
    "          'epoch': 20,\n",
    "          'transform':{\n",
    "              'name': 'get_default_transforms',\n",
    "              'image_size': 384\n",
    "          },\n",
    "          'test_loader': {\n",
    "              'batch_size': 32,\n",
    "              'shuffle': False,\n",
    "              'num_workers': os.cpu_count(),\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "          },\n",
    "          'model':{\n",
    "              'name': 'swin_large_patch4_window12_384',\n",
    "              'output_dim': 1\n",
    "          },\n",
    "          'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config_exp049 = Box(config_exp049)\n",
    "\n",
    "#054\n",
    "config_exp054 = {'exp_name':'exp054',\n",
    "          'seed': 2021,\n",
    "          'root': '/kaggle/input/petfinder-pawpularity-score/', \n",
    "          'n_splits': 5,\n",
    "          'transform':{\n",
    "              'name': 'get_default_transforms',\n",
    "              'image_size': 224\n",
    "          },\n",
    "          'test_loader': {\n",
    "              'batch_size': 32,\n",
    "              'shuffle': False,\n",
    "              'num_workers': os.cpu_count(),\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "          },\n",
    "          'model':{\n",
    "              'name': 'swin_large_patch4_window7_224',\n",
    "              'output_dim': 1\n",
    "          },\n",
    "          'optimizer':{\n",
    "              'name': 'optim.AdamW',\n",
    "              'params':{\n",
    "                  'lr': 1e-5\n",
    "              },\n",
    "          },\n",
    "          'scheduler':{\n",
    "              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "              'params':{\n",
    "                  'T_0': 20,\n",
    "                  'eta_min': 1e-4,\n",
    "              }\n",
    "          },\n",
    "          'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config_exp054 = Box(config_exp054)\n",
    "\n",
    "#060\n",
    "config_exp060 = {'exp_name':'exp060',\n",
    "          'seed': 2021,\n",
    "          'root': '/kaggle/input/petfinder-pawpularity-score/', \n",
    "          'n_splits': 5,\n",
    "          'transform':{\n",
    "              'name': 'get_default_transforms',\n",
    "              'image_size': 224\n",
    "          },\n",
    "          'test_loader': {\n",
    "              'batch_size': 32,\n",
    "              'shuffle': False,\n",
    "              'num_workers': os.cpu_count(),\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "          },\n",
    "          'model':{\n",
    "              'name': 'swin_large_patch4_window7_224_in22k',\n",
    "              'output_dim': 1\n",
    "          },\n",
    "          'optimizer':{\n",
    "              'name': 'optim.AdamW',\n",
    "              'params':{\n",
    "                  'lr': 1e-5\n",
    "              },\n",
    "          },\n",
    "          'scheduler':{\n",
    "              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "              'params':{\n",
    "                  'T_0': 20,\n",
    "                  'eta_min': 1e-4,\n",
    "              }\n",
    "          },\n",
    "          'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config_exp060 = Box(config_exp060)\n",
    "\n",
    "#065\n",
    "config_exp065 = {'exp_name':'exp065',\n",
    "          'seed': 2021,\n",
    "          'root': '/kaggle/input/petfinder-pawpularity-score/', \n",
    "          'n_splits': 5,\n",
    "          'transform':{\n",
    "              'name': 'get_default_transforms',\n",
    "              'image_size': 384\n",
    "          },\n",
    "          'test_loader': {\n",
    "              'batch_size': 32,\n",
    "              'shuffle': False,\n",
    "              'num_workers': os.cpu_count(),\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "          },\n",
    "          'model':{\n",
    "              'name': 'swin_large_patch4_window12_384',\n",
    "              'output_dim': 1\n",
    "          },\n",
    "          'optimizer':{\n",
    "              'name': 'optim.AdamW',\n",
    "              'params':{\n",
    "                  'lr': 1e-5\n",
    "              },\n",
    "          },\n",
    "          'scheduler':{\n",
    "              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "              'params':{\n",
    "                  'T_0': 20,\n",
    "                  'eta_min': 1e-4,\n",
    "              }\n",
    "          },\n",
    "          'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config_exp065 = Box(config_exp065)\n",
    "\n",
    "#069\n",
    "config_exp069 = {'exp_name':'exp069',\n",
    "          'seed': 2021,\n",
    "          'root': '/kaggle/input/petfinder-pawpularity-score/', \n",
    "          'n_splits': 5,\n",
    "          'transform':{\n",
    "              'name': 'get_default_transforms',\n",
    "              'image_size': 224\n",
    "          },\n",
    "          'test_loader': {\n",
    "              'batch_size': 32,\n",
    "              'shuffle': False,\n",
    "              'num_workers': os.cpu_count(),\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "          },\n",
    "          'model':{\n",
    "              'name': 'swin_large_patch4_window7_224',\n",
    "              'output_dim': 1\n",
    "          },\n",
    "          'optimizer':{\n",
    "              'name': 'optim.AdamW',\n",
    "              'params':{\n",
    "                  'lr': 1e-5\n",
    "              },\n",
    "          },\n",
    "          'scheduler':{\n",
    "              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "              'params':{\n",
    "                  'T_0': 20,\n",
    "                  'eta_min': 1e-4,\n",
    "              }\n",
    "          },\n",
    "          'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config_exp069 = Box(config_exp069)\n",
    "\n",
    "#074\n",
    "config_exp074 = {'exp_name':'exp074',\n",
    "          'seed': 2021,\n",
    "          'root': '/kaggle/input/petfinder-pawpularity-score/', \n",
    "          'n_splits': 5,\n",
    "          'transform':{\n",
    "              'name': 'get_default_transforms',\n",
    "              'image_size': 224\n",
    "          },\n",
    "          'test_loader': {\n",
    "              'batch_size': 32,\n",
    "              'shuffle': False,\n",
    "              'num_workers': os.cpu_count(),\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "          },\n",
    "          'model':{\n",
    "              'name': 'tf_efficientnetv2_b1',\n",
    "              'output_dim': 1\n",
    "          },\n",
    "          'optimizer':{\n",
    "              'name': 'optim.AdamW',\n",
    "              'params':{\n",
    "                  'lr': 1e-5\n",
    "              },\n",
    "          },\n",
    "          'scheduler':{\n",
    "              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "              'params':{\n",
    "                  'T_0': 20,\n",
    "                  'eta_min': 1e-4,\n",
    "              }\n",
    "          },\n",
    "          'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config_exp074 = Box(config_exp074)\n",
    "\n",
    "class PetfinderDataset_exp049(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        self._X = df[\"Id\"].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, label\n",
    "        return image\n",
    "\n",
    "class PetfinderDataset_exp054(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        dense_feature_cols = [\n",
    "            'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n",
    "            ]\n",
    "        self._X = df[\"Id\"].values\n",
    "        self.dense_features = df[dense_feature_cols].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "\n",
    "        features = self.dense_features[idx, :]\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, features, label\n",
    "        return image, features\n",
    "\n",
    "class PetfinderDataset_exp060(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        dense_feature_cols = [\n",
    "            'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n",
    "            'height', 'width', 'aspect'\n",
    "            ]\n",
    "        self._X = df[\"Id\"].values\n",
    "        self.dense_features = df[dense_feature_cols].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "\n",
    "        features = self.dense_features[idx, :]\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, features, label\n",
    "        return image, features    \n",
    "\n",
    "class PetfinderDataset_exp065(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        self._X = df[\"Id\"].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, label\n",
    "        return image\n",
    "\n",
    "class PetfinderDataset_exp069(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        dense_feature_cols = [\n",
    "            'height', 'width', 'aspect'\n",
    "            ]\n",
    "        self._X = df[\"Id\"].values\n",
    "        self.dense_features = df[dense_feature_cols].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "\n",
    "        features = self.dense_features[idx, :]\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, features, label\n",
    "        return image, features\n",
    "\n",
    "class PetfinderDataset_exp074(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        dense_feature_cols = [\n",
    "            'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n",
    "            'height', 'width', 'aspect'\n",
    "            ]\n",
    "        self._X = df[\"Id\"].values\n",
    "        self.dense_features = df[dense_feature_cols].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "\n",
    "        features = self.dense_features[idx, :]\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, features, label\n",
    "        return image, features\n",
    "    \n",
    "class PetfinderDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        test_df,\n",
    "        cfg,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._test_df = test_df\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def __create_dataset(self, train=True):\n",
    "        \n",
    "        if self._cfg.exp_name=='exp049':\n",
    "            return (\n",
    "                PetfinderDataset_exp049(self._test_df, self._cfg.transform.image_size)\n",
    "                if train\n",
    "                else PetfinderDataset_exp049(self._test_df, self._cfg.transform.image_size)\n",
    "            )\n",
    "        if self._cfg.exp_name=='exp054':\n",
    "            return (\n",
    "                PetfinderDataset_exp054(self._test_df, self._cfg.transform.image_size)\n",
    "                if train\n",
    "                else PetfinderDataset_exp054(self._test_df, self._cfg.transform.image_size)\n",
    "            )\n",
    "        if self._cfg.exp_name=='exp060':\n",
    "            return (\n",
    "                PetfinderDataset_exp060(self._test_df, self._cfg.transform.image_size)\n",
    "                if train\n",
    "                else PetfinderDataset_exp060(self._test_df, self._cfg.transform.image_size)\n",
    "            )\n",
    "        if self._cfg.exp_name=='exp065':\n",
    "            return (\n",
    "                PetfinderDataset_exp065(self._test_df, self._cfg.transform.image_size)\n",
    "                if train\n",
    "                else PetfinderDataset_exp065(self._test_df, self._cfg.transform.image_size)\n",
    "            )\n",
    "        if self._cfg.exp_name=='exp069':\n",
    "            return (\n",
    "                PetfinderDataset_exp069(self._test_df, self._cfg.transform.image_size)\n",
    "                if train\n",
    "                else PetfinderDataset_exp069(self._test_df, self._cfg.transform.image_size)\n",
    "            )\n",
    "        if self._cfg.exp_name=='exp074':\n",
    "            return (\n",
    "                PetfinderDataset_exp074(self._test_df, self._cfg.transform.image_size)\n",
    "                if train\n",
    "                else PetfinderDataset_exp074(self._test_df, self._cfg.transform.image_size)\n",
    "            )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = self.__create_dataset(True)\n",
    "        return DataLoader(dataset, **self._cfg.test_loader)\n",
    "    \n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "def get_default_transforms():\n",
    "    transform = {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ]\n",
    "        ),\n",
    "        \"val\": T.Compose(\n",
    "            [\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "    return transform\n",
    "\n",
    "def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    assert alpha > 0, \"alpha should be larger than 0\"\n",
    "    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n",
    "    target_a, target_b = y, y[rand_index]\n",
    "    return mixed_x, target_a, target_b, lam\n",
    "    \n",
    "class Model_exp049(pl.LightningModule):\n",
    "    def __init__(self, cfg, val_losses=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(self.cfg.loss)()\n",
    "        self.transform = get_default_transforms()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.val_losses = val_losses \n",
    "\n",
    "    def __build_model(self):\n",
    "        self.backbone = create_model(\n",
    "            self.cfg.model.name, pretrained=False, num_classes=0, in_chans=3\n",
    "        )\n",
    "        num_features = self.backbone.num_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        out = self.fc(f)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return {'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "        images = self.transform[mode](images)\n",
    "        \n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train':\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n",
    "            logits = self.forward(mix_images).squeeze(1)\n",
    "            loss = self._criterion(logits, target_a) * lam +                 (1 - lam) * self._criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images).squeeze(1)\n",
    "            loss = self._criterion(logits, labels)\n",
    "        \n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        \n",
    "        return loss, pred, labels\n",
    "\n",
    "class Model_exp054(pl.LightningModule):\n",
    "    def __init__(self, cfg, val_losses=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(self.cfg.loss)()\n",
    "        self.transform = get_default_transforms()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.val_losses = val_losses \n",
    "\n",
    "    def __build_model(self):\n",
    "        self.backbone = self.backbone = PoolFormerModels.poolformer_m36(pretrained=False)\n",
    "        self.backbone.head = nn.Linear(self.backbone.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(128+12, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image, features):\n",
    "        x = self.get_feature(image)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        out = self.dense2(x)\n",
    "        return out\n",
    "\n",
    "    def get_feature(self, image):\n",
    "        x = self.backbone(image)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return {'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, feature, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "        images = self.transform[mode](images)\n",
    "        \n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train':\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=self.cfg.mixup.alpha)\n",
    "            logits = self.forward(mix_images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, target_a) * lam + (1 - lam) * self._criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, labels)\n",
    "        \n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        \n",
    "        return loss, pred, labels\n",
    "\n",
    "class Model_exp060(pl.LightningModule):\n",
    "    def __init__(self, cfg, val_losses=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(self.cfg.loss)()\n",
    "        self.transform = get_default_transforms()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.val_losses = val_losses \n",
    "\n",
    "    def __build_model(self):\n",
    "        self.backbone = create_model(\n",
    "            self.cfg.model.name, pretrained=False, num_classes=128, in_chans=3\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(128+15, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image, features):\n",
    "        x = self.get_feature(image)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        out = self.dense2(x)\n",
    "        return out\n",
    "\n",
    "    def get_feature(self, image):\n",
    "        x = self.backbone(image)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return {'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, feature, labels = batch\n",
    "        feature = feature.float()\n",
    "        labels = labels.float() / 100.0\n",
    "        images = self.transform[mode](images)\n",
    "        \n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train':\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=self.cfg.mixup.alpha)\n",
    "            logits = self.forward(mix_images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, target_a) * lam + (1 - lam) * self._criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, labels)\n",
    "        \n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        \n",
    "        return loss, pred, labels\n",
    "\n",
    "class Model_exp065(pl.LightningModule):\n",
    "    def __init__(self, cfg, val_losses=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(self.cfg.loss)()\n",
    "        self.transform = get_default_transforms()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.val_losses = val_losses \n",
    "\n",
    "    def __build_model(self):\n",
    "        self.backbone = create_model(\n",
    "            self.cfg.model.name, pretrained=False, num_classes=0, in_chans=3\n",
    "        )\n",
    "        num_features = self.backbone.num_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        out = self.fc(f)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return {'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, feature, labels = batch\n",
    "        feature = feature.float()\n",
    "        labels = labels.float() / 100.0\n",
    "        images = self.transform[mode](images)\n",
    "        \n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train':\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=self.cfg.mixup.alpha)\n",
    "            logits = self.forward(mix_images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, target_a) * lam + (1 - lam) * self._criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, labels)\n",
    "        \n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        \n",
    "        return loss, pred, labels\n",
    "    \n",
    "class Model_exp069(pl.LightningModule):\n",
    "    def __init__(self, cfg, val_losses=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(self.cfg.loss)()\n",
    "        self.transform = get_default_transforms()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.val_losses = val_losses \n",
    "\n",
    "    def __build_model(self):\n",
    "        self.backbone = create_model(\n",
    "            self.cfg.model.name, pretrained=False, num_classes=128, in_chans=3\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(128+3, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "        num_features = self.backbone.num_features\n",
    "\n",
    "    def forward(self, image, features):\n",
    "        x = self.backbone(image)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout2(x)\n",
    "        out = self.dense2(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return {'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, feature, labels = batch\n",
    "        feature = feature.float()\n",
    "        labels = labels.float() / 100.0\n",
    "        images = self.transform[mode](images)\n",
    "        \n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train':\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=self.cfg.mixup.alpha)\n",
    "            logits = self.forward(mix_images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, target_a) * lam + (1 - lam) * self._criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, labels)\n",
    "        \n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        \n",
    "        return loss, pred, labels\n",
    "    \n",
    "class Model_exp074(pl.LightningModule):\n",
    "    def __init__(self, cfg, val_losses=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self._criterion = eval(self.cfg.loss)()\n",
    "        self.transform = get_default_transforms()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.val_losses = val_losses \n",
    "\n",
    "    def __build_model(self):\n",
    "        self.backbone = create_model(\n",
    "            self.cfg.model.name, pretrained=False, num_classes=128, in_chans=3\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(128+15, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "        num_features = self.backbone.num_features\n",
    "\n",
    "    def forward(self, image, features):\n",
    "        x = self.get_feature(image)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout2(x)\n",
    "        out = self.dense2(x)\n",
    "        return out\n",
    "\n",
    "    def get_feature(self, image):\n",
    "        x = self.backbone(image)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'train')\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return {'loss': loss, 'pred': pred, 'labels': labels}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, labels = self.__share_step(batch, 'val')\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return {'pred': pred, 'labels': labels}\n",
    "    \n",
    "    def __share_step(self, batch, mode):\n",
    "        images, feature, labels = batch\n",
    "        feature = feature.float()\n",
    "        labels = labels.float() / 100.0\n",
    "        images = self.transform[mode](images)\n",
    "        \n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train':\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=self.cfg.mixup.alpha)\n",
    "            logits = self.forward(mix_images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, target_a) * lam + (1 - lam) * self._criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, feature).squeeze(1)\n",
    "            loss = self._criterion(logits, labels)\n",
    "        \n",
    "        pred = logits.sigmoid().detach().cpu() * 100.\n",
    "        labels = labels.detach().cpu() * 100.\n",
    "        \n",
    "        return loss, pred, labels\n",
    "    \n",
    "def transform_get_image_shape_describe(input_df): \n",
    "    pathes = input_df['Id'].values\n",
    "    shapes = []\n",
    "    for path in tqdm(pathes):\n",
    "        img = Image.open(path)\n",
    "        height, width = img.height, img.width\n",
    "        shapes.append([height, width])\n",
    "    input_df[[\"height\", \"width\"]] = shapes\n",
    "    input_df[\"aspect\"] = input_df[\"height\"] / input_df[\"width\"]\n",
    "    height_mean = 904.2843018563358\n",
    "    height_std = 156.90598049629264\n",
    "    width_mean = 804.4262510088781\n",
    "    width_std = 270.21192072081044\n",
    "    if len(input_df)==8:#testだと全部同じ大きさで標準化ミスるからエラー除去でいれる。\n",
    "        input_df['height'] = input_df['height'].fillna(0)\n",
    "        input_df['width'] = input_df['width'].fillna(0)\n",
    "    else:\n",
    "        input_df['height'] = input_df['height'].apply(lambda x: (x-height_mean)/ height_std)\n",
    "        input_df['width'] = input_df['width'].apply(lambda x: (x-width_mean)/ width_std)\n",
    "\n",
    "    print(f'height_mean{height_mean}_std{height_std}')\n",
    "    print(f'width_mean{width_mean}_std{width_std}')\n",
    "    return input_df\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(config_exp049.root, \"test.csv\"))\n",
    "test = test_df.copy()\n",
    "test_df[\"Id\"] = test_df[\"Id\"].apply(lambda x: os.path.join(config_exp049.root, \"test\", x + \".jpg\"))\n",
    "test_df = transform_get_image_shape_describe(test_df)\n",
    "dataloader_exp049 = PetfinderDataModule(test_df, config_exp049).test_dataloader()\n",
    "dataloader_exp054 = PetfinderDataModule(test_df, config_exp054).test_dataloader()\n",
    "dataloader_exp060 = PetfinderDataModule(test_df, config_exp060).test_dataloader()\n",
    "dataloader_exp065 = PetfinderDataModule(test_df, config_exp065).test_dataloader()\n",
    "dataloader_exp069 = PetfinderDataModule(test_df, config_exp069).test_dataloader()\n",
    "dataloader_exp074 = PetfinderDataModule(test_df, config_exp074).test_dataloader()\n",
    "\n",
    "\n",
    "def get_predict_feature(test_loader, model, device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    predicts = []\n",
    "    for images, features in test_loader:\n",
    "        images = images.to(device)\n",
    "        features = features.to(device).float()\n",
    "        images = get_default_transforms()['val'](images)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            predict = model(images, features).sigmoid().detach().cpu().numpy() * 100\n",
    "        predicts.append(predict)\n",
    "    predicts = np.concatenate(predicts)\n",
    "    return predicts\n",
    "\n",
    "def get_predict(test_loader, model, device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    predicts = []\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        images = get_default_transforms()['val'](images)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            predict = model(images).sigmoid().detach().cpu().numpy() * 100\n",
    "        predicts.append(predict)\n",
    "    predicts = np.concatenate(predicts)\n",
    "    return predicts\n",
    "\n",
    "IMG_PREDICTS = []\n",
    "tmp = []\n",
    "for fold in tqdm(range(config_exp049.n_splits)):\n",
    "    model = Model_exp049(config_exp049)\n",
    "    model_path = \"../input/petfinder-334model/exp049\"\n",
    "    model.load_state_dict(torch.load(f'{model_path}/fold{fold}/best_loss_fold{fold}.pth'))\n",
    "    predicts = get_predict(dataloader_exp049, model, 'cuda')\n",
    "    tmp.append(predicts)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS.append(tmp)\n",
    "    \n",
    "tmp = []\n",
    "for fold in tqdm(range(config_exp054.n_splits)):\n",
    "    model = Model_exp054(config_exp054)\n",
    "    model_path = \"../input/petfinder-224model/exp054\"\n",
    "    model.load_state_dict(torch.load(f'{model_path}/fold{fold}/best_loss_fold{fold}.pth'))\n",
    "    predicts = get_predict_feature(dataloader_exp054, model, 'cuda')\n",
    "    tmp.append(predicts)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS.append(tmp)\n",
    "\n",
    "tmp = []\n",
    "for fold in tqdm(range(config_exp060.n_splits)):\n",
    "    model = Model_exp060(config_exp060)\n",
    "    model_path = \"../input/petfinder-224model/exp060\"\n",
    "    model.load_state_dict(torch.load(f'{model_path}/fold{fold}/best_loss_fold{fold}.pth'))\n",
    "    predicts = get_predict_feature(dataloader_exp060, model, 'cuda')\n",
    "    tmp.append(predicts)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS.append(tmp)\n",
    "\n",
    "tmp = []\n",
    "for fold in tqdm(range(config_exp065.n_splits)):\n",
    "    model = Model_exp065(config_exp065)\n",
    "    model_path = \"../input/petfinder-334model/exp065\"\n",
    "    model.load_state_dict(torch.load(f'{model_path}/fold{fold}/best_loss_fold{fold}.pth'))\n",
    "    predicts = get_predict(dataloader_exp065, model, 'cuda')\n",
    "    tmp.append(predicts)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS.append(tmp)\n",
    "\n",
    "tmp = []\n",
    "for fold in tqdm(range(config_exp069.n_splits)):\n",
    "    model = Model_exp069(config_exp069)\n",
    "    model_path = \"../input/petfinder-224model/exp069\"\n",
    "    model.load_state_dict(torch.load(f'{model_path}/fold{fold}/best_loss_fold{fold}.pth'))\n",
    "    predicts = get_predict_feature(dataloader_exp069, model, 'cuda')\n",
    "    tmp.append(predicts)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS.append(tmp)\n",
    "\n",
    "tmp = []\n",
    "for fold in tqdm(range(config_exp074.n_splits)):\n",
    "    model = Model_exp074(config_exp074)\n",
    "    model_path = \"../input/petfinder-224model/exp074\"\n",
    "    model.load_state_dict(torch.load(f'{model_path}/fold{fold}/best_loss_fold{fold}.pth'))\n",
    "    predicts = get_predict_feature(dataloader_exp074, model, 'cuda')\n",
    "    tmp.append(predicts)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS.append(tmp)\n",
    "\n",
    "def load_ensemble_model(path):\n",
    "    with open(path, mode='rb') as fp:\n",
    "        clf = pickle.load(fp)\n",
    "    return clf\n",
    "\n",
    "ensemble_predict = []\n",
    "ensemble_model_exp_path = '../input/d/ktakita/petfinder-ensumble/exp085_ensumble'\n",
    "for fold in range(5):\n",
    "    X = np.concatenate([IMG_PREDICTS[0][fold],\n",
    "                        IMG_PREDICTS[1][fold],\n",
    "                        IMG_PREDICTS[2][fold],\n",
    "                        IMG_PREDICTS[3][fold],\n",
    "                        IMG_PREDICTS[4][fold],\n",
    "                        IMG_PREDICTS[5][fold]],  \n",
    "                       axis=1)\n",
    "    ensemble_model_path = f'{ensemble_model_exp_path}/fold{fold}_{config_ensemble.model}.pickle'\n",
    "    model = load_ensemble_model(ensemble_model_path)\n",
    "    pred = model.predict(X)\n",
    "    ensemble_predict.append(pred)\n",
    "    \n",
    "pd.DataFrame(ensemble_predict)\n",
    "\n",
    "predict = np.mean(ensemble_predict, 0)\n",
    "\n",
    "predictions = predict\n",
    "test['Pawpularity'] = predictions\n",
    "test[['Id', 'Pawpularity']].to_csv('submission_at.csv', index=False)\n",
    "#display(test[['Id', 'Pawpularity']].head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee21b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:31:49.494105Z",
     "iopub.status.busy": "2022-01-13T14:31:49.493507Z",
     "iopub.status.idle": "2022-01-13T14:34:05.275620Z",
     "shell.execute_reply": "2022-01-13T14:34:05.276239Z",
     "shell.execute_reply.started": "2022-01-13T13:58:26.044203Z"
    },
    "papermill": {
     "duration": 135.802574,
     "end_time": "2022-01-13T14:34:05.276479",
     "exception": false,
     "start_time": "2022-01-13T14:31:49.473905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "height_mean904.2843018563358_std156.90598049629264\n",
      "width_mean804.4262510088781_std270.21192072081044\n",
      "exp108\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "sys.path.append('../input/pythonbox')\n",
    "from box import Box\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "from timm import create_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from pytorch_grad_cam import GradCAMPlusPlus\n",
    "#from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "#sys.path.append('../input/poolformer-master')\n",
    "#import models as PoolFormerModels #poolformer\n",
    "\n",
    "print(pl.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "sys.path.append(f'../input/petfinder-scripts')\n",
    "\n",
    "\n",
    "class PetfinderDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        test_df,\n",
    "        dataset,\n",
    "        cfg,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._test_df = test_df\n",
    "        self._dataset = dataset\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def __create_dataset(self, train=True):\n",
    "        return (\n",
    "            self._dataset(self._test_df, self._cfg.transform.image_size)\n",
    "            if train\n",
    "            else self._dataset(self._test_df, self._cfg.transform.image_size)\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = self.__create_dataset(True)\n",
    "        self._cfg.val_loader.batch_size = 32\n",
    "        self._cfg.val_loader.num_workers = os.cpu_count()\n",
    "        return DataLoader(dataset, **self._cfg.val_loader)\n",
    "\n",
    "def transform_get_image_shape_describe(input_df): \n",
    "    pathes = input_df['Id'].values\n",
    "    shapes = []\n",
    "    for path in tqdm(pathes):\n",
    "        img = Image.open(path)\n",
    "        height, width = img.height, img.width\n",
    "        shapes.append([height, width])\n",
    "    input_df[[\"height\", \"width\"]] = shapes\n",
    "    input_df[\"aspect\"] = input_df[\"height\"] / input_df[\"width\"]\n",
    "    height_mean = 904.2843018563358\n",
    "    height_std = 156.90598049629264\n",
    "    width_mean = 804.4262510088781\n",
    "    width_std = 270.21192072081044\n",
    "    if len(test_df)==8:#testだと全部同じ大きさで標準化ミスるからエラー除去でいれる。\n",
    "        input_df['height'] = input_df['height'].fillna(0)\n",
    "        input_df['width'] = input_df['width'].fillna(0)\n",
    "    else:\n",
    "        input_df['height'] = input_df['height'].apply(lambda x: (x-height_mean)/ height_std)\n",
    "        input_df['width'] = input_df['width'].apply(lambda x: (x-width_mean)/ width_std)\n",
    "\n",
    "    print(f'height_mean{height_mean}_std{height_std}')\n",
    "    print(f'width_mean{width_mean}_std{width_std}')\n",
    "    return input_df\n",
    "    \n",
    "def get_predict_feature(model, test_loader, transforms,device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    predicts = []\n",
    "    for images, features in test_loader:\n",
    "        images = images.to(device)\n",
    "        features = features.to(device).float()\n",
    "        images = transforms()['val'](images)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            predict = model(images, features).sigmoid().detach().cpu().numpy() * 100\n",
    "        predicts.append(predict)\n",
    "    predicts = np.concatenate(predicts)\n",
    "    return predicts\n",
    "\n",
    "def get_predict(model, test_loader, transforms,device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    predicts = []\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        images = transforms()['val'](images)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            predict = model(images).sigmoid().detach().cpu().numpy() * 100\n",
    "        predicts.append(predict)\n",
    "    predicts = np.concatenate(predicts)\n",
    "    return predicts\n",
    "\n",
    "def model_load(model, exp_name, model_path):\n",
    "    if exp_name == 'exp092' or exp_name == 'exp100':\n",
    "        model.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "import exp108\n",
    "\n",
    "test_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n",
    "test_df[\"Id\"] = test_df[\"Id\"].apply(lambda x: os.path.join('../input/petfinder-pawpularity-score', \"test\", x + \".jpg\"))\n",
    "test_df = transform_get_image_shape_describe(test_df)\n",
    "\n",
    "IMG_PREDICTS = []\n",
    "exp_name = 'exp108'\n",
    "print(exp_name)\n",
    "config = eval(exp_name).config\n",
    "config.model.pretrain = False\n",
    "dataloader = PetfinderDataModule(test_df, \n",
    "                                 eval(exp_name).PetfinderDataset, \n",
    "                                 config).test_dataloader()\n",
    "\n",
    "tmp = []\n",
    "for fold in tqdm(range(config.n_splits)):\n",
    "    model = eval(exp_name).Model(config)\n",
    "    model_path = glob.glob(os.path.join('../input/petfinder-exp108', f'{exp_name}/fold{fold}/best_loss_fold{fold}.*'))[0]\n",
    "    model.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "    predicts = get_predict_feature(model, dataloader, eval(exp_name).get_default_transforms, 'cuda')\n",
    "\n",
    "    tmp.append(predicts)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "IMG_PREDICTS = tmp\n",
    "\n",
    "#predict make\n",
    "preds = []\n",
    "fold_num = len(IMG_PREDICTS)\n",
    "for fold in range(fold_num):\n",
    "    preds.append(IMG_PREDICTS[fold] / fold_num)\n",
    "predict = np.sum(preds, 0)\n",
    "\n",
    "predictions = predict\n",
    "\n",
    "test = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\n",
    "test['Pawpularity'] = predictions\n",
    "test[['Id', 'Pawpularity']].to_csv('submission_exp108.csv', index=False)\n",
    "#display(test[['Id', 'Pawpularity']].head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39870cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:34:05.320434Z",
     "iopub.status.busy": "2022-01-13T14:34:05.319590Z",
     "iopub.status.idle": "2022-01-13T14:35:45.171064Z",
     "shell.execute_reply": "2022-01-13T14:35:45.171533Z",
     "shell.execute_reply.started": "2022-01-13T14:01:08.778272Z"
    },
    "papermill": {
     "duration": 99.877913,
     "end_time": "2022-01-13T14:35:45.171704",
     "exception": false,
     "start_time": "2022-01-13T14:34:05.293791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "# Python Libraries\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Pytorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Pytorch Image Models\n",
    "from timm import create_model\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class PetfinderDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, image_size=224):\n",
    "        self._X = df[\"Id\"].values\n",
    "        self.meta = df[feature_cols].values\n",
    "        self._y = None\n",
    "#         if \"Pawpularity\" in df.keys():\n",
    "#             self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Compose([\n",
    "                                        T.Resize(image_size),  # 1\n",
    "                                        T.CenterCrop([image_size, image_size]),  # 2\n",
    "                                    ]\n",
    "                                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "        features = torch.FloatTensor(self.meta[idx, :])\n",
    "        \n",
    "        return image, features \n",
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "def get_default_transforms():\n",
    "    transform = {\n",
    "        \"val\": T.Compose(\n",
    "            [\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "    return transform   \n",
    "# ====================================================\n",
    "# model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.backbone = create_model(model_name=self.cfg.model_name,\n",
    "                                     pretrained=pretrained,\n",
    "                                     in_chans=self.cfg.in_chans,\n",
    "                                     num_classes=0)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(3084, self.cfg.target_size)\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.LazyLinear(self.cfg.target_size)\n",
    "#         )\n",
    "    def get_feature(self, x, features):\n",
    "        return self.backbone(x)\n",
    "        \n",
    "    def forward(self, x, features):\n",
    "        f = self.backbone(x) # (bs, embedding_size)\n",
    "        f = self.dropout1(f)\n",
    "        if features.shape[1] != 0:\n",
    "            f = torch.cat([f, features],dim=1)\n",
    "            f =  self.dropout2(f)\n",
    "        out = self.fc(f)\n",
    "        return out\n",
    "    \n",
    "def get_model(cfg):\n",
    "    model = CustomModel(cfg, pretrained=False)\n",
    "    return model\n",
    "\n",
    "def predict(model, loader):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    predicts = []\n",
    "    for batch in tqdm(loader):\n",
    "        images, features = batch\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        images = get_default_transforms()['val'](images)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            predict = model(images, features).sigmoid().detach().cpu().numpy() * 100\n",
    "        predicts.append(predict)\n",
    "    predicts = np.concatenate(predicts)\n",
    "    return predicts\n",
    "\n",
    "# ====================================================\n",
    "# Config\n",
    "# ====================================================\n",
    "class CFG_029:\n",
    "    debug = False\n",
    "    model_name = 'dm_nfnet_f3'\n",
    "    img_size = 512\n",
    "    in_chans = 3\n",
    "    n_fold = 5\n",
    "    target_size = 1\n",
    "    # DataLoader\n",
    "    loader = {\n",
    "        \"valid\": {\n",
    "            \"batch_size\": 32,\n",
    "            \"num_workers\": 4,\n",
    "            \"shuffle\": False,\n",
    "            \"pin_memory\": True,\n",
    "            \"drop_last\": False\n",
    "        }\n",
    "    }\n",
    "    # exp020\n",
    "    feature_cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n",
    "        ]\n",
    "\n",
    "df_test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n",
    "df_test[\"Id\"] = df_test[\"Id\"].apply(lambda x: os.path.join('../input/petfinder-pawpularity-score', \"test\", x + \".jpg\"))\n",
    "    \n",
    "loader = DataLoader(PetfinderDataset(df_test, CFG_029.feature_cols, CFG_029.img_size),**CFG_029.loader['valid'])\n",
    "\n",
    "tmp = []\n",
    "for i in tqdm(range(CFG_029.n_fold)):\n",
    "    model = get_model(CFG_029)\n",
    "    model.load_state_dict(torch.load(f'../input/pet2teyomodel1/exp029_1759169/exp029_fold{i}_best.pth', map_location=device))\n",
    "    predicts = predict(model, loader)\n",
    "    tmp.append(predicts)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "test = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\n",
    "test['Pawpularity'] = np.mean(tmp,axis=0)\n",
    "test[['Id', 'Pawpularity']].to_csv('submission_exp029.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815ab838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:35:45.204493Z",
     "iopub.status.busy": "2022-01-13T14:35:45.199832Z",
     "iopub.status.idle": "2022-01-13T14:45:26.455235Z",
     "shell.execute_reply": "2022-01-13T14:45:26.454767Z",
     "shell.execute_reply.started": "2022-01-13T14:03:03.93702Z"
    },
    "papermill": {
     "duration": 581.273047,
     "end_time": "2022-01-13T14:45:26.455369",
     "exception": false,
     "start_time": "2022-01-13T14:35:45.182322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n",
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [03:03<03:46, 28.34s/it]../input/pytorch-1-10-1/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 13/13 [09:27<00:00, 43.64s/it]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "#import pandas as pd\n",
    "#if pd.read_csv('../input/petfinder-pawpularity-score/test.csv').shape[0] == 8:\n",
    "#    exit()\n",
    "    \n",
    "import sys\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "sys.path = [\"../input/pytorch-1-10-1/\"] + sys.path\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "from timm import create_model\n",
    "\n",
    "from fastai.vision.all import *\n",
    "print(torch.__version__)\n",
    "\n",
    "set_seed(999, reproducible=True)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset_path = Path('../input/petfinder-pawpularity-score/')\n",
    "\n",
    "seed = 999\n",
    "set_seed(seed, reproducible=True)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True\n",
    "\n",
    "def petfinder_rmse(input,target):\n",
    "    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n",
    "\n",
    "test_df = pd.read_csv(dataset_path/'test.csv')\n",
    "test_df.head()\n",
    "\n",
    "test_df['Pawpularity'] = [1]*len(test_df)\n",
    "test_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\n",
    "test_df = test_df.drop(columns=['Id'])\n",
    "test_df['norm_score'] = test_df['Pawpularity'] / 100\n",
    "\n",
    "def get_data(img_size):\n",
    "    dls = ImageDataLoaders.from_df(test_df, #pass in train DataFrame\n",
    "                               #valid_col='is_valid', #\n",
    "                               seed=999, #seed\n",
    "                               fn_col='path', #filename/path is in the second column of the DataFrame\n",
    "                               label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                               y_block=RegressionBlock, #The type of target\n",
    "                               bs=BATCH_SIZE, #pass in batch size\n",
    "                               num_workers=8,\n",
    "                               item_tfms=Resize(img_size), #pass in item_tfms\n",
    "                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n",
    "    \n",
    "    return dls\n",
    "\n",
    "\n",
    "\n",
    "model_weights = {'exp7_cait_m36_384': 0.10573687177566875,\n",
    " 'exp4_xcit_small_24_p16_384_dist': 0.09017084075938603,\n",
    " 'exp4_crossvit_18_dagger_408': 0.0864555998708494,\n",
    " 'exp4_xcit_small_24_p8_384_dist': 0.08478909740799544,\n",
    " 'exp15_vit_base_patch16_224_miil_in21k': 0.08388133976905879,\n",
    " 'exp7_swin_large_patch4_window12_384_in22k': 0.08162600824050978,\n",
    " 'exp9_cait_m36_384': 0.07951668818830163,\n",
    " 'exp7_vit_base_patch16_224_miil_in21k': 0.07448271317999128,\n",
    " 'exp7_swin_base_patch4_window12_384': 0.07014647726439097,\n",
    " 'exp7_jx_nest_base': 0.06841255969223342,\n",
    " 'exp8_vit_base_patch16_224_miil_in21k': 0.06359775694462852,\n",
    " 'exp7_vit_base_r50_s16_384': 0.061862705948120524,\n",
    " 'exp15_vit_large_patch16_224': 0.0546458052004623}\n",
    "\n",
    "\n",
    "N_FOLDS = 5\n",
    "all_preds = []\n",
    "\n",
    "for path, w in tqdm(model_weights.items()):\n",
    "    model_name = path.split('_', 1)[-1]\n",
    "    try:\n",
    "        img_size = int(model_name.split('_')[-1])\n",
    "    except:\n",
    "        try:\n",
    "            img_size = int(model_name.split('_')[-2])\n",
    "        except:\n",
    "            img_size = 224\n",
    "    dls = get_data(img_size)\n",
    "    \n",
    "    def proc(pred):\n",
    "        return pred\n",
    "    num_classes = 1\n",
    "    if 'exp4_' in path:\n",
    "        model_dir = '../input/model-exp4-0106/pet'\n",
    "        loss = BCEWithLogitsLossFlat()\n",
    "    elif 'exp7_' in path:\n",
    "        model_dir = '../input/model-exp7-0106/pet'\n",
    "        loss = BCEWithLogitsLossFlat()\n",
    "    elif 'exp8_' in path:\n",
    "        model_dir = '../input/model-exp8-9-15-0106/pet'\n",
    "        loss = MSELossFlat()\n",
    "    elif 'exp9_' in path:\n",
    "        model_dir = '../input/model-exp8-9-15-0106/pet' \n",
    "        loss = CrossEntropyLossFlat()\n",
    "        num_classes = 100\n",
    "        def proc(pred):\n",
    "            return (pred.argmax(axis=1) + 1) / 100\n",
    "    elif 'exp15_' in path:\n",
    "        model_dir = '../input/model-exp8-9-15-0106/pet'\n",
    "        loss = MSELossFlat()\n",
    "        def proc(pred):\n",
    "            return (np.exp(pred) / 100).clip(0.01, 1)\n",
    "    else:\n",
    "        raise\n",
    "            \n",
    "    for i in range(N_FOLDS):\n",
    "        model = create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "        model.load_state_dict(torch.load(f'{model_dir}/{path}/{model_name}_{i}.pth'))\n",
    "\n",
    "        learn = Learner(dls, model, \n",
    "                        loss_func=loss,\n",
    "                        metrics=petfinder_rmse).to_fp16()\n",
    "\n",
    "        test_dl = dls.test_dl(test_df)\n",
    "\n",
    "        preds, _ = learn.get_preds(dl=test_dl)\n",
    "        #preds, _ = learn.tta(dl=test_dl, n=2, beta=0)\n",
    "        \n",
    "        preds = proc(preds).flatten()\n",
    "        \n",
    "        all_preds.append(preds * w / N_FOLDS)\n",
    "\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    del dls\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\n",
    "preds = np.sum(np.stack(all_preds), axis=0)\n",
    "sample_df['Pawpularity'] = preds*100\n",
    "sample_df.to_csv('submission_tkm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1973dd9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:45:26.485883Z",
     "iopub.status.busy": "2022-01-13T14:45:26.485115Z",
     "iopub.status.idle": "2022-01-13T14:45:26.528658Z",
     "shell.execute_reply": "2022-01-13T14:45:26.529042Z",
     "shell.execute_reply.started": "2022-01-13T14:13:11.165502Z"
    },
    "papermill": {
     "duration": 0.062263,
     "end_time": "2022-01-13T14:45:26.529173",
     "exception": false,
     "start_time": "2022-01-13T14:45:26.466910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4128bae22183829d2b5fea10effdb0c3</th>\n",
       "      <td>49.200574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43a2262d7738e3d420d453815151079e</th>\n",
       "      <td>49.188477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e429cead1848a298432a0acad014c9d</th>\n",
       "      <td>49.115084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80bc3ccafcc51b66303c2c263aa38486</th>\n",
       "      <td>49.370076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f49844c382931444e68dffbe20228f4</th>\n",
       "      <td>49.026995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b03f7041962238a7c9d6537e22f9b017</th>\n",
       "      <td>49.265595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c978013571258ed6d4637f6e8cc9d6a3</th>\n",
       "      <td>49.417783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e0de453c1bffc20c22b072b34b54e50f</th>\n",
       "      <td>49.135504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pawpularity\n",
       "Id                                           \n",
       "4128bae22183829d2b5fea10effdb0c3    49.200574\n",
       "43a2262d7738e3d420d453815151079e    49.188477\n",
       "4e429cead1848a298432a0acad014c9d    49.115084\n",
       "80bc3ccafcc51b66303c2c263aa38486    49.370076\n",
       "8f49844c382931444e68dffbe20228f4    49.026995\n",
       "b03f7041962238a7c9d6537e22f9b017    49.265595\n",
       "c978013571258ed6d4637f6e8cc9d6a3    49.417783\n",
       "e0de453c1bffc20c22b072b34b54e50f    49.135504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub_at = pd.read_csv('submission_at.csv', index_col='Id')\n",
    "sub_tkm = pd.read_csv('submission_tkm.csv', index_col='Id')\n",
    "sub_exp108 = pd.read_csv('submission_exp108.csv', index_col='Id')\n",
    "sub_exp029 = pd.read_csv('submission_exp029.csv', index_col='Id')\n",
    "\n",
    "#[0.502754   0.18612928 0.31658946]\n",
    "#[0.51461806 0.16874229 0.3218239 ]\n",
    "#['exp108', 'exp029', 'oof0(tkmsan)', 'oof1(at)']\n",
    "#[0.29673496 0.17641786 0.41963073 0.11312639]\n",
    "sub = (0.29673496 * sub_exp108 + 0.17641786 * sub_exp029 + 0.41963073 * sub_tkm + 0.11312639 * sub_at)\n",
    "\n",
    "sub.to_csv('submission_ens.csv')\n",
    "sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c10926ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:45:26.561839Z",
     "iopub.status.busy": "2022-01-13T14:45:26.561236Z",
     "iopub.status.idle": "2022-01-13T14:48:26.593811Z",
     "shell.execute_reply": "2022-01-13T14:48:26.594236Z",
     "shell.execute_reply.started": "2022-01-13T14:13:11.292814Z"
    },
    "papermill": {
     "duration": 180.0525,
     "end_time": "2022-01-13T14:48:26.594416",
     "exception": false,
     "start_time": "2022-01-13T14:45:26.541916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f2492cab1f401f8f489ae0a4942231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DEBUG = pd.read_csv('../input/petfinder-pawpularity-score/test.csv').shape[0] == 8\n",
    "\n",
    "df1 = pd.read_csv('../input/pet-data/df1_train_test_v5.csv')\n",
    "\n",
    "if DEBUG:\n",
    "    df2 = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n",
    "    df2['pred'] = 0.5\n",
    "    df2['path'] = df2['Id'].map(lambda x:str(f'../input/petfinder-pawpularity-score/train/{x}.jpg'))\n",
    "else:\n",
    "    df2 = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n",
    "    df2['pred'] = df2['Id'].map(pd.read_csv('submission_ens.csv', index_col='Id')['Pawpularity']) / 100\n",
    "    df2['path'] = df2['Id'].map(lambda x:str(f'../input/petfinder-pawpularity-score/test/{x}.jpg'))\n",
    "    \n",
    "df2['hash'] = [imagehash.average_hash(Image.open(x))\n",
    "                    for x in tqdm(df2['path'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ef0e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:48:26.630442Z",
     "iopub.status.busy": "2022-01-13T14:48:26.625523Z",
     "iopub.status.idle": "2022-01-13T14:48:27.649989Z",
     "shell.execute_reply": "2022-01-13T14:48:27.650875Z",
     "shell.execute_reply.started": "2022-01-13T14:16:14.901319Z"
    },
    "papermill": {
     "duration": 1.044134,
     "end_time": "2022-01-13T14:48:27.651078",
     "exception": false,
     "start_time": "2022-01-13T14:48:26.606944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1['hash'] = df1['hash'].astype(str)\n",
    "df2['hash'] = df2['hash'].astype(str)\n",
    "df = pd.merge(df2, df1, how='left', on='hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20bf48ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T14:48:27.707011Z",
     "iopub.status.busy": "2022-01-13T14:48:27.706216Z",
     "iopub.status.idle": "2022-01-13T14:48:31.016903Z",
     "shell.execute_reply": "2022-01-13T14:48:31.016117Z",
     "shell.execute_reply.started": "2022-01-13T14:16:15.732112Z"
    },
    "papermill": {
     "duration": 3.345285,
     "end_time": "2022-01-13T14:48:31.017028",
     "exception": false,
     "start_time": "2022-01-13T14:48:27.671743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0007de18844b0dbbb5e1f607da0606e0</th>\n",
       "      <td>60.485896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009c66b9439883ba2750fb825e1d7db</th>\n",
       "      <td>45.796748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013fd999caf9a3efe1352ca1b0d937e</th>\n",
       "      <td>56.013132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018df346ac9c1d8413cfcc888ca8246</th>\n",
       "      <td>51.530062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001dc955e10590d3ca4673f034feeef2</th>\n",
       "      <td>51.243319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbfa0383c34dc513c95560d6e1fdb57</th>\n",
       "      <td>49.588228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffcc8532d76436fc79e50eb2e5238e45</th>\n",
       "      <td>51.530062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffdf2e8673a1da6fb80342fa3b119a20</th>\n",
       "      <td>51.530062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff19e2ce11718548fa1c5d039a5192a</th>\n",
       "      <td>46.039270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8e47c766799c9e12f3cb3d66ad228</th>\n",
       "      <td>51.530062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pawpularity\n",
       "Id                                           \n",
       "0007de18844b0dbbb5e1f607da0606e0    60.485896\n",
       "0009c66b9439883ba2750fb825e1d7db    45.796748\n",
       "0013fd999caf9a3efe1352ca1b0d937e    56.013132\n",
       "0018df346ac9c1d8413cfcc888ca8246    51.530062\n",
       "001dc955e10590d3ca4673f034feeef2    51.243319\n",
       "...                                       ...\n",
       "ffbfa0383c34dc513c95560d6e1fdb57    49.588228\n",
       "ffcc8532d76436fc79e50eb2e5238e45    51.530062\n",
       "ffdf2e8673a1da6fb80342fa3b119a20    51.530062\n",
       "fff19e2ce11718548fa1c5d039a5192a    46.039270\n",
       "fff8e47c766799c9e12f3cb3d66ad228    51.530062\n",
       "\n",
       "[9912 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if df.shape[0] > 0:\n",
    "    with open('../input/0113-2nd-stage-gbdt-fixed-w-newmodels3/list_model_lgb_last_comp_all.pkl', 'rb') as f:\n",
    "        models = pickle.load(f)\n",
    "    df['len_desc'] = df['Description'].fillna('').map(len)\n",
    "    df['Name'] = df['Name'].fillna('').replace('No Name Yet', '')\n",
    "    df['len_name'] = df['Name'].map(len)\n",
    "    \n",
    "    pred = 0\n",
    "    for model in models:\n",
    "        pred += model.predict(df[model.feature_name()])\n",
    "    pred /= len(models)\n",
    "    \n",
    "    df_pred = pd.DataFrame()\n",
    "    df_pred['Id'] = df['Id'].values\n",
    "    df_pred['Pawpularity'] = (pred * 100).clip(1, 100)\n",
    "    \n",
    "    sub = df_pred.groupby('Id')[['Pawpularity']].mean()\n",
    "    #sub = pd.read_csv('submission_ens.csv')\n",
    "    #sub = sub[~sub['Id'].isin(df_pred['Id'])].append(df_pred)\n",
    "    #sub = sub.set_index('Id').sort_index()\n",
    "    #sub.to_csv('submission.csv')\n",
    "else:\n",
    "    sub = pd.read_csv('submission_ens.csv', index_col='Id')\n",
    "    #sub.to_csv('submission.csv', index=False)\n",
    "    \n",
    "\n",
    "pred = sub['Pawpularity'].values / 100\n",
    "#mu = pred.mean()\n",
    "#pred = (pred - mu) + 0.38362035973750004\n",
    "pred = pred.clip(0.01, 1)\n",
    "\n",
    "sub['Pawpularity'] = pred * 100\n",
    "sub.to_csv('submission.csv')\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1261.928194,
   "end_time": "2022-01-13T14:48:32.166523",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-13T14:27:30.238329",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "180c2d4bcfb94d36812a8a4144881bd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "535bcf944b014521818f417f0e168c21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e21cb5b039441d4be8166e20c1adf8e",
       "max": 9912.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_62d699743863402bb228a7f65ab2baa9",
       "value": 9912.0
      }
     },
     "62d699743863402bb228a7f65ab2baa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "81e15818c02641d6bd8011d47f3a3e8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89ac56c8a32b44f89aa9c21db18d4b27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81e15818c02641d6bd8011d47f3a3e8b",
       "placeholder": "​",
       "style": "IPY_MODEL_b9e148d04b454d079d62b6315dedeb35",
       "value": "100%"
      }
     },
     "9e21cb5b039441d4be8166e20c1adf8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a794639b016642639fd7779a30f80d58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad3664b326334d50a1681a97efb6c275": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9e148d04b454d079d62b6315dedeb35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e9df661832cd48e6973a270c44356690": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad3664b326334d50a1681a97efb6c275",
       "placeholder": "​",
       "style": "IPY_MODEL_180c2d4bcfb94d36812a8a4144881bd5",
       "value": " 9912/9912 [02:58&lt;00:00, 61.51it/s]"
      }
     },
     "f3f2492cab1f401f8f489ae0a4942231": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_89ac56c8a32b44f89aa9c21db18d4b27",
        "IPY_MODEL_535bcf944b014521818f417f0e168c21",
        "IPY_MODEL_e9df661832cd48e6973a270c44356690"
       ],
       "layout": "IPY_MODEL_a794639b016642639fd7779a30f80d58"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
